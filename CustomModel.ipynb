{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "jprv3FqEFvyY",
    "outputId": "5bafb2c1-4176-4ef9-8dfe-e2347875938d",
    "tags": []
   },
   "outputs": [],
   "source": [
    "%pip install mosaicml\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Looking in indexes: https://pypi.org/simple, https://pip.repos.neuron.amazonaws.com\n",
      "Collecting imbalanced-learn\n",
      "  Using cached imbalanced_learn-0.11.0-py3-none-any.whl (235 kB)\n",
      "Requirement already satisfied: numpy>=1.17.3 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from imbalanced-learn) (1.24.3)\n",
      "Requirement already satisfied: scipy>=1.5.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from imbalanced-learn) (1.10.1)\n",
      "Requirement already satisfied: scikit-learn>=1.0.2 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from imbalanced-learn) (1.2.2)\n",
      "Requirement already satisfied: joblib>=1.1.1 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from imbalanced-learn) (1.2.0)\n",
      "Requirement already satisfied: threadpoolctl>=2.0.0 in /home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages (from imbalanced-learn) (3.1.0)\n",
      "Installing collected packages: imbalanced-learn\n",
      "Successfully installed imbalanced-learn-0.11.0\n",
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    }
   ],
   "source": [
    "%pip install imbalanced-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "TPFTCgoF9saI",
    "outputId": "cbdecba4-4ec6-4569-b4ce-213ce9960c1b",
    "tags": []
   },
   "outputs": [],
   "source": [
    "# from google.colab import drive\n",
    "# drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "id": "4H7nE9dQx9-o",
    "tags": []
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "\n",
    "import torch.optim as optim\n",
    "from composer import Trainer\n",
    "import composer\n",
    "from composer.algorithms import BlurPool\n",
    "from composer.loggers import InMemoryLogger\n",
    "\n",
    "from composer.models import ComposerModel\n",
    "import time\n",
    "\n",
    "\n",
    "from tqdm import tqdm\n",
    "from glob import glob\n",
    "import seaborn as sns\n",
    "import pprint as pp\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.utils import resample\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow import keras\n",
    "from tensorflow.keras import layers\n",
    "from keras.utils import np_utils\n",
    "\n",
    "import itertools\n",
    "\n",
    "import cv2\n",
    "from PIL import Image\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "id": "Jp--AgK9wngb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from pathlib  import Path\n",
    "import pathlib\n",
    "dataset_path='./data/ham10000'\n",
    "meta_df=pd.read_csv(dataset_path+'/HAM10000_metadata')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 424
    },
    "id": "LXkKXsf6x2g_",
    "outputId": "e7a27074-c20e-41f4-c285-25513dd32297",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>lesion_id</th>\n",
       "      <th>image_id</th>\n",
       "      <th>dx</th>\n",
       "      <th>dx_type</th>\n",
       "      <th>age</th>\n",
       "      <th>sex</th>\n",
       "      <th>localization</th>\n",
       "      <th>dataset</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0027419</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>HAM_0000118</td>\n",
       "      <td>ISIC_0025030</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0026769</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>HAM_0002730</td>\n",
       "      <td>ISIC_0025661</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>scalp</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>HAM_0001466</td>\n",
       "      <td>ISIC_0031633</td>\n",
       "      <td>bkl</td>\n",
       "      <td>histo</td>\n",
       "      <td>75.0</td>\n",
       "      <td>male</td>\n",
       "      <td>ear</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10010</th>\n",
       "      <td>HAM_0002867</td>\n",
       "      <td>ISIC_0033084</td>\n",
       "      <td>akiec</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10011</th>\n",
       "      <td>HAM_0002867</td>\n",
       "      <td>ISIC_0033550</td>\n",
       "      <td>akiec</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10012</th>\n",
       "      <td>HAM_0002867</td>\n",
       "      <td>ISIC_0033536</td>\n",
       "      <td>akiec</td>\n",
       "      <td>histo</td>\n",
       "      <td>40.0</td>\n",
       "      <td>male</td>\n",
       "      <td>abdomen</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10013</th>\n",
       "      <td>HAM_0000239</td>\n",
       "      <td>ISIC_0032854</td>\n",
       "      <td>akiec</td>\n",
       "      <td>histo</td>\n",
       "      <td>80.0</td>\n",
       "      <td>male</td>\n",
       "      <td>face</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>10014</th>\n",
       "      <td>HAM_0003521</td>\n",
       "      <td>ISIC_0032258</td>\n",
       "      <td>mel</td>\n",
       "      <td>histo</td>\n",
       "      <td>70.0</td>\n",
       "      <td>female</td>\n",
       "      <td>back</td>\n",
       "      <td>vidir_modern</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10015 rows Ã— 8 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         lesion_id      image_id     dx dx_type   age     sex localization  \\\n",
       "0      HAM_0000118  ISIC_0027419    bkl   histo  80.0    male        scalp   \n",
       "1      HAM_0000118  ISIC_0025030    bkl   histo  80.0    male        scalp   \n",
       "2      HAM_0002730  ISIC_0026769    bkl   histo  80.0    male        scalp   \n",
       "3      HAM_0002730  ISIC_0025661    bkl   histo  80.0    male        scalp   \n",
       "4      HAM_0001466  ISIC_0031633    bkl   histo  75.0    male          ear   \n",
       "...            ...           ...    ...     ...   ...     ...          ...   \n",
       "10010  HAM_0002867  ISIC_0033084  akiec   histo  40.0    male      abdomen   \n",
       "10011  HAM_0002867  ISIC_0033550  akiec   histo  40.0    male      abdomen   \n",
       "10012  HAM_0002867  ISIC_0033536  akiec   histo  40.0    male      abdomen   \n",
       "10013  HAM_0000239  ISIC_0032854  akiec   histo  80.0    male         face   \n",
       "10014  HAM_0003521  ISIC_0032258    mel   histo  70.0  female         back   \n",
       "\n",
       "            dataset  \n",
       "0      vidir_modern  \n",
       "1      vidir_modern  \n",
       "2      vidir_modern  \n",
       "3      vidir_modern  \n",
       "4      vidir_modern  \n",
       "...             ...  \n",
       "10010  vidir_modern  \n",
       "10011  vidir_modern  \n",
       "10012  vidir_modern  \n",
       "10013  vidir_modern  \n",
       "10014  vidir_modern  \n",
       "\n",
       "[10015 rows x 8 columns]"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "meta_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "id": "ozWxmDagy0oF",
    "tags": []
   },
   "outputs": [],
   "source": [
    "data = pd.read_csv(dataset_path+\"/hmnist_28_28_RGB.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "YjOqhibJzeJ7",
    "outputId": "9517af80-65de-43e0-8ed4-61aa4163843a",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['pixel0000', 'pixel0001', 'pixel0002', 'pixel0003', 'pixel0004',\n",
       "       'pixel0005', 'pixel0006', 'pixel0007', 'pixel0008', 'pixel0009',\n",
       "       ...\n",
       "       'pixel2343', 'pixel2344', 'pixel2345', 'pixel2346', 'pixel2347',\n",
       "       'pixel2348', 'pixel2349', 'pixel2350', 'pixel2351', 'label'],\n",
       "      dtype='object', length=2353)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.columns"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "id": "1zebH_0xzgNo",
    "tags": []
   },
   "outputs": [],
   "source": [
    "yData = data['label']\n",
    "XData = data.drop(columns = ['label'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "xkfjGmsOzr2F",
    "outputId": "766bd663-6ecf-4a9a-8500-6943941586d6",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "nv       6705\n",
       "mel      1113\n",
       "bkl      1099\n",
       "bcc       514\n",
       "akiec     327\n",
       "vasc      142\n",
       "df        115\n",
       "Name: dx, dtype: int64"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "distribution = meta_df['dx'].value_counts()\n",
    "distribution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-B8oq4jHzvk9",
    "outputId": "63fc5835-fcd7-4528-bc02-0585343d0530",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4    6705\n",
       "6    1113\n",
       "2    1099\n",
       "1     514\n",
       "0     327\n",
       "5     142\n",
       "3     115\n",
       "Name: label, dtype: int64"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dist = data['label'].value_counts()\n",
    "dist"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "nfvavdDEzxwN",
    "outputId": "6d18ab11-8134-48d3-f012-a8177f73acd0",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Axes: >"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "distribution.plot()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "id": "ivxduchQzzpV",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "id": "ijDiOeKkz1mb",
    "tags": []
   },
   "outputs": [],
   "source": [
    "sampler = RandomOverSampler()\n",
    "XData,yData  = sampler.fit_resample(XData,yData)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "-2rH0J6dz3S-",
    "outputId": "d0a5b8fb-fecd-4fd3-f838-7d5f941cb2c9",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((46935, 2352), (46935,))"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XData.shape, yData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "k3xP-bhrz5Ws",
    "outputId": "ceabb139-de6c-4217-d97a-a88c7ee4fa2f",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(46935, 28, 28, 3)"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "XData = np.array(XData).reshape((-1, 28, 28, 3))\n",
    "XData = XData / 255\n",
    "XData.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "id": "jc_dae4Vz7J4",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "id": "ywnq0Krbz882",
    "tags": []
   },
   "outputs": [],
   "source": [
    "Xtrain, Xtest, Ytrain, Ytest = train_test_split(XData,yData, test_size=0.2)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "1OFipdR6z-vj",
    "outputId": "74012c4d-1bbc-46a7-ccf9-fe225d3b8f83",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((37548, 28, 28, 3), (9387, 28, 28, 3))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Xtrain.shape, Xtest.shape\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "id": "oiXRdbWN0BNX",
    "tags": []
   },
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.layers import Activation, Dropout, Flatten, Dense\n",
    "import tensorflow as tf\n",
    "\n",
    "img_width, img_height = 28,28\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "id": "CBNLmVI_0C-7",
    "tags": []
   },
   "outputs": [],
   "source": [
    "input_shape = (img_width, img_height, 3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "id": "_qQDws4c0LE_",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Conv2D(32, (2, 2), padding='same', input_shape=input_shape))\n",
    "model.add(Activation('swish'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(32, (2, 2), padding='same'))\n",
    "model.add(Activation('swish'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "\n",
    "\n",
    "model.add(Conv2D(64, (2, 2), padding='same'))\n",
    "model.add(Activation('swish'))\n",
    "model.add(MaxPooling2D(pool_size=(2, 1)))\n",
    "\n",
    "\n",
    "model.add(Flatten())\n",
    "model.add(Dense(64))\n",
    "model.add(Activation('swish'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(7))\n",
    "model.add(Activation('softmax'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "id": "Wwas6DeV0Nra",
    "tags": []
   },
   "outputs": [],
   "source": [
    "model.compile(loss='sparse_categorical_crossentropy',\n",
    "optimizer='nadam',\n",
    "metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "id": "frl-QSJC0P71",
    "tags": []
   },
   "outputs": [],
   "source": [
    "callback = tf.keras.callbacks.ModelCheckpoint(filepath='best_model.h5',\n",
    "                                                  monitor='val_acc', mode='max',\n",
    "                                                 verbose=1)\n",
    "\n",
    "early_stopping = tf.keras.callbacks.EarlyStopping(patience=10, restore_best_weights=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Hf57C6_G0SCb",
    "outputId": "d04e5ee5-05c2-49f1-a2ca-809655398486",
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "1174/1174 [==============================] - ETA: 0s - loss: 1.3593 - accuracy: 0.4674\n",
      "Epoch 1: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 10s 4ms/step - loss: 1.3593 - accuracy: 0.4674 - val_loss: 1.0460 - val_accuracy: 0.5980\n",
      "Epoch 2/100\n",
      "1174/1174 [==============================] - ETA: 0s - loss: 1.0279 - accuracy: 0.6096\n",
      "Epoch 2: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 1.0279 - accuracy: 0.6096 - val_loss: 0.8551 - val_accuracy: 0.6808\n",
      "Epoch 3/100\n",
      "1170/1174 [============================>.] - ETA: 0s - loss: 0.8402 - accuracy: 0.6859\n",
      "Epoch 3: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.8401 - accuracy: 0.6859 - val_loss: 0.7132 - val_accuracy: 0.7271\n",
      "Epoch 4/100\n",
      "1165/1174 [============================>.] - ETA: 0s - loss: 0.7017 - accuracy: 0.7395\n",
      "Epoch 4: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.7020 - accuracy: 0.7395 - val_loss: 0.5818 - val_accuracy: 0.7792\n",
      "Epoch 5/100\n",
      "1164/1174 [============================>.] - ETA: 0s - loss: 0.6003 - accuracy: 0.7733\n",
      "Epoch 5: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.5999 - accuracy: 0.7734 - val_loss: 0.4731 - val_accuracy: 0.8238\n",
      "Epoch 6/100\n",
      "1174/1174 [==============================] - ETA: 0s - loss: 0.5308 - accuracy: 0.7985\n",
      "Epoch 6: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.5308 - accuracy: 0.7985 - val_loss: 0.4090 - val_accuracy: 0.8505\n",
      "Epoch 7/100\n",
      "1170/1174 [============================>.] - ETA: 0s - loss: 0.4677 - accuracy: 0.8214\n",
      "Epoch 7: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.4675 - accuracy: 0.8216 - val_loss: 0.3930 - val_accuracy: 0.8560\n",
      "Epoch 8/100\n",
      "1171/1174 [============================>.] - ETA: 0s - loss: 0.4224 - accuracy: 0.8370\n",
      "Epoch 8: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.4224 - accuracy: 0.8371 - val_loss: 0.3176 - val_accuracy: 0.8862\n",
      "Epoch 9/100\n",
      "1162/1174 [============================>.] - ETA: 0s - loss: 0.3923 - accuracy: 0.8496\n",
      "Epoch 9: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.3919 - accuracy: 0.8497 - val_loss: 0.3754 - val_accuracy: 0.8655\n",
      "Epoch 10/100\n",
      "1171/1174 [============================>.] - ETA: 0s - loss: 0.3653 - accuracy: 0.8599\n",
      "Epoch 10: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.3652 - accuracy: 0.8600 - val_loss: 0.2719 - val_accuracy: 0.8983\n",
      "Epoch 11/100\n",
      "1160/1174 [============================>.] - ETA: 0s - loss: 0.3361 - accuracy: 0.8704\n",
      "Epoch 11: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.3367 - accuracy: 0.8702 - val_loss: 0.2555 - val_accuracy: 0.9057\n",
      "Epoch 12/100\n",
      "1173/1174 [============================>.] - ETA: 0s - loss: 0.3166 - accuracy: 0.8773\n",
      "Epoch 12: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.3165 - accuracy: 0.8773 - val_loss: 0.2371 - val_accuracy: 0.9113\n",
      "Epoch 13/100\n",
      "1160/1174 [============================>.] - ETA: 0s - loss: 0.3018 - accuracy: 0.8851\n",
      "Epoch 13: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.3016 - accuracy: 0.8851 - val_loss: 0.2371 - val_accuracy: 0.9119\n",
      "Epoch 14/100\n",
      "1169/1174 [============================>.] - ETA: 0s - loss: 0.2903 - accuracy: 0.8876\n",
      "Epoch 14: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.2903 - accuracy: 0.8876 - val_loss: 0.2262 - val_accuracy: 0.9178\n",
      "Epoch 15/100\n",
      "1171/1174 [============================>.] - ETA: 0s - loss: 0.2722 - accuracy: 0.8964\n",
      "Epoch 15: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.2724 - accuracy: 0.8964 - val_loss: 0.2096 - val_accuracy: 0.9215\n",
      "Epoch 16/100\n",
      "1160/1174 [============================>.] - ETA: 0s - loss: 0.2617 - accuracy: 0.8998\n",
      "Epoch 16: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.2611 - accuracy: 0.9000 - val_loss: 0.1838 - val_accuracy: 0.9338\n",
      "Epoch 17/100\n",
      "1167/1174 [============================>.] - ETA: 0s - loss: 0.2498 - accuracy: 0.9046\n",
      "Epoch 17: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.2501 - accuracy: 0.9044 - val_loss: 0.1796 - val_accuracy: 0.9353\n",
      "Epoch 18/100\n",
      "1161/1174 [============================>.] - ETA: 0s - loss: 0.2403 - accuracy: 0.9069\n",
      "Epoch 18: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.2405 - accuracy: 0.9068 - val_loss: 0.2082 - val_accuracy: 0.9268\n",
      "Epoch 19/100\n",
      "1163/1174 [============================>.] - ETA: 0s - loss: 0.2302 - accuracy: 0.9120\n",
      "Epoch 19: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.2300 - accuracy: 0.9121 - val_loss: 0.1826 - val_accuracy: 0.9352\n",
      "Epoch 20/100\n",
      "1169/1174 [============================>.] - ETA: 0s - loss: 0.2259 - accuracy: 0.9128\n",
      "Epoch 20: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.2258 - accuracy: 0.9127 - val_loss: 0.1757 - val_accuracy: 0.9365\n",
      "Epoch 21/100\n",
      "1161/1174 [============================>.] - ETA: 0s - loss: 0.2092 - accuracy: 0.9193\n",
      "Epoch 21: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.2093 - accuracy: 0.9190 - val_loss: 0.1776 - val_accuracy: 0.9379\n",
      "Epoch 22/100\n",
      "1162/1174 [============================>.] - ETA: 0s - loss: 0.2061 - accuracy: 0.9208\n",
      "Epoch 22: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.2060 - accuracy: 0.9208 - val_loss: 0.1625 - val_accuracy: 0.9451\n",
      "Epoch 23/100\n",
      "1161/1174 [============================>.] - ETA: 0s - loss: 0.2032 - accuracy: 0.9218\n",
      "Epoch 23: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.2039 - accuracy: 0.9214 - val_loss: 0.1696 - val_accuracy: 0.9377\n",
      "Epoch 24/100\n",
      "1168/1174 [============================>.] - ETA: 0s - loss: 0.1964 - accuracy: 0.9251\n",
      "Epoch 24: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1961 - accuracy: 0.9252 - val_loss: 0.1525 - val_accuracy: 0.9462\n",
      "Epoch 25/100\n",
      "1162/1174 [============================>.] - ETA: 0s - loss: 0.1835 - accuracy: 0.9302\n",
      "Epoch 25: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1830 - accuracy: 0.9305 - val_loss: 0.1403 - val_accuracy: 0.9510\n",
      "Epoch 26/100\n",
      "1170/1174 [============================>.] - ETA: 0s - loss: 0.1818 - accuracy: 0.9303\n",
      "Epoch 26: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1817 - accuracy: 0.9303 - val_loss: 0.1322 - val_accuracy: 0.9531\n",
      "Epoch 27/100\n",
      "1173/1174 [============================>.] - ETA: 0s - loss: 0.1779 - accuracy: 0.9336\n",
      "Epoch 27: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1779 - accuracy: 0.9336 - val_loss: 0.1384 - val_accuracy: 0.9508\n",
      "Epoch 28/100\n",
      "1172/1174 [============================>.] - ETA: 0s - loss: 0.1691 - accuracy: 0.9366\n",
      "Epoch 28: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1690 - accuracy: 0.9366 - val_loss: 0.1338 - val_accuracy: 0.9537\n",
      "Epoch 29/100\n",
      "1174/1174 [==============================] - ETA: 0s - loss: 0.1721 - accuracy: 0.9351\n",
      "Epoch 29: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1721 - accuracy: 0.9351 - val_loss: 0.1301 - val_accuracy: 0.9545\n",
      "Epoch 30/100\n",
      "1172/1174 [============================>.] - ETA: 0s - loss: 0.1683 - accuracy: 0.9366\n",
      "Epoch 30: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1682 - accuracy: 0.9367 - val_loss: 0.1233 - val_accuracy: 0.9543\n",
      "Epoch 31/100\n",
      "1169/1174 [============================>.] - ETA: 0s - loss: 0.1628 - accuracy: 0.9381\n",
      "Epoch 31: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1629 - accuracy: 0.9381 - val_loss: 0.1282 - val_accuracy: 0.9571\n",
      "Epoch 32/100\n",
      "1160/1174 [============================>.] - ETA: 0s - loss: 0.1584 - accuracy: 0.9396\n",
      "Epoch 32: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1581 - accuracy: 0.9398 - val_loss: 0.1083 - val_accuracy: 0.9644\n",
      "Epoch 33/100\n",
      "1160/1174 [============================>.] - ETA: 0s - loss: 0.1581 - accuracy: 0.9414\n",
      "Epoch 33: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1580 - accuracy: 0.9413 - val_loss: 0.1340 - val_accuracy: 0.9550\n",
      "Epoch 34/100\n",
      "1174/1174 [==============================] - ETA: 0s - loss: 0.1470 - accuracy: 0.9442\n",
      "Epoch 34: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1470 - accuracy: 0.9442 - val_loss: 0.1100 - val_accuracy: 0.9615\n",
      "Epoch 35/100\n",
      "1173/1174 [============================>.] - ETA: 0s - loss: 0.1499 - accuracy: 0.9431\n",
      "Epoch 35: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1499 - accuracy: 0.9431 - val_loss: 0.1221 - val_accuracy: 0.9574\n",
      "Epoch 36/100\n",
      "1173/1174 [============================>.] - ETA: 0s - loss: 0.1472 - accuracy: 0.9451\n",
      "Epoch 36: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1472 - accuracy: 0.9451 - val_loss: 0.1298 - val_accuracy: 0.9531\n",
      "Epoch 37/100\n",
      "1174/1174 [==============================] - ETA: 0s - loss: 0.1411 - accuracy: 0.9456\n",
      "Epoch 37: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1411 - accuracy: 0.9456 - val_loss: 0.1056 - val_accuracy: 0.9657\n",
      "Epoch 38/100\n",
      "1162/1174 [============================>.] - ETA: 0s - loss: 0.1412 - accuracy: 0.9462\n",
      "Epoch 38: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1410 - accuracy: 0.9463 - val_loss: 0.0972 - val_accuracy: 0.9689\n",
      "Epoch 39/100\n",
      "1161/1174 [============================>.] - ETA: 0s - loss: 0.1383 - accuracy: 0.9471\n",
      "Epoch 39: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1389 - accuracy: 0.9469 - val_loss: 0.1161 - val_accuracy: 0.9635\n",
      "Epoch 40/100\n",
      "1174/1174 [==============================] - ETA: 0s - loss: 0.1399 - accuracy: 0.9487\n",
      "Epoch 40: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1399 - accuracy: 0.9487 - val_loss: 0.1126 - val_accuracy: 0.9637\n",
      "Epoch 41/100\n",
      "1161/1174 [============================>.] - ETA: 0s - loss: 0.1301 - accuracy: 0.9510\n",
      "Epoch 41: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1305 - accuracy: 0.9510 - val_loss: 0.0985 - val_accuracy: 0.9696\n",
      "Epoch 42/100\n",
      "1174/1174 [==============================] - ETA: 0s - loss: 0.1282 - accuracy: 0.9519\n",
      "Epoch 42: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1282 - accuracy: 0.9519 - val_loss: 0.1068 - val_accuracy: 0.9660\n",
      "Epoch 43/100\n",
      "1171/1174 [============================>.] - ETA: 0s - loss: 0.1326 - accuracy: 0.9502\n",
      "Epoch 43: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1327 - accuracy: 0.9502 - val_loss: 0.1019 - val_accuracy: 0.9692\n",
      "Epoch 44/100\n",
      "1163/1174 [============================>.] - ETA: 0s - loss: 0.1281 - accuracy: 0.9523\n",
      "Epoch 44: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1280 - accuracy: 0.9524 - val_loss: 0.1219 - val_accuracy: 0.9609\n",
      "Epoch 45/100\n",
      "1174/1174 [==============================] - ETA: 0s - loss: 0.1233 - accuracy: 0.9540\n",
      "Epoch 45: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1233 - accuracy: 0.9540 - val_loss: 0.1055 - val_accuracy: 0.9660\n",
      "Epoch 46/100\n",
      "1169/1174 [============================>.] - ETA: 0s - loss: 0.1251 - accuracy: 0.9530\n",
      "Epoch 46: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 5ms/step - loss: 0.1251 - accuracy: 0.9531 - val_loss: 0.1105 - val_accuracy: 0.9646\n",
      "Epoch 47/100\n",
      "1167/1174 [============================>.] - ETA: 0s - loss: 0.1224 - accuracy: 0.9549\n",
      "Epoch 47: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1226 - accuracy: 0.9547 - val_loss: 0.0955 - val_accuracy: 0.9708\n",
      "Epoch 48/100\n",
      "1161/1174 [============================>.] - ETA: 0s - loss: 0.1217 - accuracy: 0.9542\n",
      "Epoch 48: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1216 - accuracy: 0.9542 - val_loss: 0.1005 - val_accuracy: 0.9687\n",
      "Epoch 49/100\n",
      "1172/1174 [============================>.] - ETA: 0s - loss: 0.1174 - accuracy: 0.9553\n",
      "Epoch 49: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1174 - accuracy: 0.9553 - val_loss: 0.1074 - val_accuracy: 0.9647\n",
      "Epoch 50/100\n",
      "1172/1174 [============================>.] - ETA: 0s - loss: 0.1180 - accuracy: 0.9551\n",
      "Epoch 50: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1180 - accuracy: 0.9551 - val_loss: 0.1037 - val_accuracy: 0.9687\n",
      "Epoch 51/100\n",
      "1161/1174 [============================>.] - ETA: 0s - loss: 0.1184 - accuracy: 0.9556\n",
      "Epoch 51: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1181 - accuracy: 0.9558 - val_loss: 0.1015 - val_accuracy: 0.9704\n",
      "Epoch 52/100\n",
      "1162/1174 [============================>.] - ETA: 0s - loss: 0.1111 - accuracy: 0.9582\n",
      "Epoch 52: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1118 - accuracy: 0.9579 - val_loss: 0.0946 - val_accuracy: 0.9723\n",
      "Epoch 53/100\n",
      "1164/1174 [============================>.] - ETA: 0s - loss: 0.1171 - accuracy: 0.9563\n",
      "Epoch 53: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1171 - accuracy: 0.9562 - val_loss: 0.1022 - val_accuracy: 0.9719\n",
      "Epoch 54/100\n",
      "1164/1174 [============================>.] - ETA: 0s - loss: 0.1124 - accuracy: 0.9584\n",
      "Epoch 54: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1123 - accuracy: 0.9584 - val_loss: 0.0982 - val_accuracy: 0.9713\n",
      "Epoch 55/100\n",
      "1160/1174 [============================>.] - ETA: 0s - loss: 0.1133 - accuracy: 0.9574\n",
      "Epoch 55: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1133 - accuracy: 0.9574 - val_loss: 0.0949 - val_accuracy: 0.9737\n",
      "Epoch 56/100\n",
      "1167/1174 [============================>.] - ETA: 0s - loss: 0.1164 - accuracy: 0.9571\n",
      "Epoch 56: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1167 - accuracy: 0.9570 - val_loss: 0.0978 - val_accuracy: 0.9718\n",
      "Epoch 57/100\n",
      "1162/1174 [============================>.] - ETA: 0s - loss: 0.1089 - accuracy: 0.9597\n",
      "Epoch 57: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1089 - accuracy: 0.9598 - val_loss: 0.1013 - val_accuracy: 0.9719\n",
      "Epoch 58/100\n",
      "1173/1174 [============================>.] - ETA: 0s - loss: 0.1043 - accuracy: 0.9622\n",
      "Epoch 58: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1043 - accuracy: 0.9622 - val_loss: 0.0892 - val_accuracy: 0.9759\n",
      "Epoch 59/100\n",
      "1168/1174 [============================>.] - ETA: 0s - loss: 0.1024 - accuracy: 0.9617\n",
      "Epoch 59: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1024 - accuracy: 0.9617 - val_loss: 0.1144 - val_accuracy: 0.9676\n",
      "Epoch 60/100\n",
      "1160/1174 [============================>.] - ETA: 0s - loss: 0.0966 - accuracy: 0.9637\n",
      "Epoch 60: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.0969 - accuracy: 0.9635 - val_loss: 0.1063 - val_accuracy: 0.9665\n",
      "Epoch 61/100\n",
      "1170/1174 [============================>.] - ETA: 0s - loss: 0.1116 - accuracy: 0.9593\n",
      "Epoch 61: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1117 - accuracy: 0.9593 - val_loss: 0.0952 - val_accuracy: 0.9717\n",
      "Epoch 62/100\n",
      "1174/1174 [==============================] - ETA: 0s - loss: 0.1032 - accuracy: 0.9614\n",
      "Epoch 62: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1032 - accuracy: 0.9614 - val_loss: 0.0956 - val_accuracy: 0.9736\n",
      "Epoch 63/100\n",
      "1174/1174 [==============================] - ETA: 0s - loss: 0.1022 - accuracy: 0.9625\n",
      "Epoch 63: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1022 - accuracy: 0.9625 - val_loss: 0.0999 - val_accuracy: 0.9689\n",
      "Epoch 64/100\n",
      "1172/1174 [============================>.] - ETA: 0s - loss: 0.0983 - accuracy: 0.9631\n",
      "Epoch 64: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.0983 - accuracy: 0.9631 - val_loss: 0.0924 - val_accuracy: 0.9741\n",
      "Epoch 65/100\n",
      "1161/1174 [============================>.] - ETA: 0s - loss: 0.1005 - accuracy: 0.9637\n",
      "Epoch 65: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.1003 - accuracy: 0.9638 - val_loss: 0.0945 - val_accuracy: 0.9734\n",
      "Epoch 66/100\n",
      "1161/1174 [============================>.] - ETA: 0s - loss: 0.0986 - accuracy: 0.9648\n",
      "Epoch 66: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.0991 - accuracy: 0.9647 - val_loss: 0.1158 - val_accuracy: 0.9658\n",
      "Epoch 67/100\n",
      "1174/1174 [==============================] - ETA: 0s - loss: 0.0928 - accuracy: 0.9658\n",
      "Epoch 67: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.0928 - accuracy: 0.9658 - val_loss: 0.0937 - val_accuracy: 0.9753\n",
      "Epoch 68/100\n",
      "1174/1174 [==============================] - ETA: 0s - loss: 0.0992 - accuracy: 0.9634\n",
      "Epoch 68: saving model to best_model.h5\n",
      "1174/1174 [==============================] - 5s 4ms/step - loss: 0.0992 - accuracy: 0.9634 - val_loss: 0.0941 - val_accuracy: 0.9744\n"
     ]
    }
   ],
   "source": [
    "history = model.fit(Xtrain,\n",
    "                    Ytrain,\n",
    "                    epochs = 100,\n",
    "                    validation_data = (Xtest, Ytest),\n",
    "                    callbacks=[callback, early_stopping])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import torch\n",
    "from torch.utils.data import DataLoader, TensorDataset\n",
    "\n",
    "# Convert numpy arrays or pandas DataFrames to PyTorch tensors\n",
    "Xtrain_tensor = torch.tensor(Xtrain, dtype=torch.float32)\n",
    "Xtest_tensor = torch.tensor(Xtest, dtype=torch.float32)\n",
    "\n",
    "# If Ytrain or Ytest are pandas Series, convert them to numpy arrays first\n",
    "Ytrain_array = Ytrain.values if isinstance(Ytrain, pd.Series) else Ytrain\n",
    "Ytest_array = Ytest.values if isinstance(Ytest, pd.Series) else Ytest\n",
    "\n",
    "# Convert numpy arrays to PyTorch tensors\n",
    "Ytrain_tensor = torch.tensor(Ytrain_array, dtype=torch.long)\n",
    "Ytest_tensor = torch.tensor(Ytest_array, dtype=torch.long)\n",
    "\n",
    "# Create TensorDatasets\n",
    "train_dataset_pytorch = TensorDataset(Xtrain_tensor, Ytrain_tensor)\n",
    "test_dataset_pytorch = TensorDataset(Xtest_tensor, Ytest_tensor)\n",
    "\n",
    "# Create DataLoaders\n",
    "BATCH_SIZE = 32\n",
    "train_loader = DataLoader(train_dataset_pytorch, batch_size=BATCH_SIZE, shuffle=True)\n",
    "test_loader = DataLoader(test_dataset_pytorch, batch_size=BATCH_SIZE, shuffle=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "id": "hY339fg9E3mk",
    "tags": []
   },
   "outputs": [],
   "source": [
    "def requirementsForModelTraining(model):\n",
    "    blurpool = BlurPool(\n",
    "    replace_convs=True, # Blur before convs\n",
    "    replace_maxpools=True, # Blur before max-pools\n",
    "    blur_first=True # Blur before conv/max-pool)\n",
    "    )\n",
    "    optimizer = optim.Adam(model.parameters(), lr=0.0001)\n",
    "    algorithms=[blurpool]\n",
    "    return algorithms, optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "id": "FcuMMdnsGr6V",
    "tags": []
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "CustomModelComposer(\n",
       "  (conv1): Conv2d(3, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "  (conv2): Conv2d(32, 32, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "  (conv3): Conv2d(32, 64, kernel_size=(2, 2), stride=(1, 1), padding=(1, 1))\n",
       "  (fc1): Linear(in_features=1024, out_features=64, bias=True)\n",
       "  (fc2): Linear(in_features=64, out_features=7, bias=True)\n",
       "  (dropout): Dropout(p=0.5, inplace=False)\n",
       "  (criterion): CrossEntropyLoss()\n",
       ")"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n",
    "class CustomModelComposer(ComposerModel):\n",
    "    def __init__(self):\n",
    "        super(CustomModelComposer, self).__init__()\n",
    "        \n",
    "        # Convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 32, kernel_size=2, padding=1)\n",
    "        self.conv2 = nn.Conv2d(32, 32, kernel_size=2, padding=1)\n",
    "        self.conv3 = nn.Conv2d(32, 64, kernel_size=2, padding=1)\n",
    "        \n",
    "        # Dense layers\n",
    "        self.fc1 = nn.Linear(64*4*4, 64)  # Adjusted size after three max pooling operations\n",
    "        self.fc2 = nn.Linear(64, 7)\n",
    "        \n",
    "        # Dropout\n",
    "        self.dropout = nn.Dropout(0.5)\n",
    "        \n",
    "        self.criterion = nn.CrossEntropyLoss()\n",
    "        \n",
    "    def forward(self, x):\n",
    "        if isinstance(x, tuple):\n",
    "            x = x[0]\n",
    "        \n",
    "        # Permute the dimensions to match PyTorch's expectations\n",
    "        x = x.permute(0, 3, 1, 2)\n",
    "\n",
    "        # First conv block\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        # Second conv block\n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        # Third conv block\n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.max_pool2d(x, 2)\n",
    "\n",
    "        # Flatten and pass through FC layers\n",
    "        x = x.contiguous().view(x.size(0), -1)\n",
    "        x = F.relu(self.fc1(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc2(x)\n",
    "        \n",
    "        return x\n",
    "    \n",
    "    def get_metrics(self, is_train: bool):\n",
    "        # You can return any metrics you want to monitor. \n",
    "        # If you don't have specific metrics, return an empty dictionary.\n",
    "        return {}\n",
    "    \n",
    "    def loss(self, outputs, targets):\n",
    "        if isinstance(targets, tuple):\n",
    "            targets = targets[0]\n",
    "        if len(targets.shape) == 4:  # [N, H, W, C]\n",
    "            targets = targets.argmax(dim=-1)  # Convert to [N, H, W] with class indices\n",
    "        targets = targets.view(targets.size(0), -1).argmax(dim=-1)  # Convert to [N] with class indices for entire image\n",
    "\n",
    "        # Add these lines for debugging\n",
    "        unique, counts = torch.unique(targets, return_counts=True)\n",
    "        print(\"Unique values in targets:\", unique)\n",
    "        print(\"Counts of unique values:\", counts)\n",
    "\n",
    "        return self.criterion(outputs, targets)\n",
    "\n",
    "\n",
    "# Instantiate the model\n",
    "custom_model_composer = CustomModelComposer()\n",
    "custom_model_composer\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "id": "tDZm1ds01_w6",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/ec2-user/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/composer/algorithms/blurpool/blurpool.py:160: NoEffectWarning: Applying BlurPool did not change any layers. No strided Conv2d or Pool2d layers were found.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "algorithms, optimizer,  = requirementsForModelTraining(custom_model_composer)\n",
    "\n",
    "\n",
    "logger = InMemoryLogger()\n",
    "trainer = Trainer(\n",
    "    model=custom_model_composer,\n",
    "    optimizers=optimizer,\n",
    "    train_dataloader=train_loader,\n",
    "    eval_dataloader=test_loader,\n",
    "    max_duration='10ep',\n",
    "    algorithms=algorithms,\n",
    "    loggers=logger\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 560
    },
    "id": "IdbYZw9AGIdz",
    "outputId": "ed7f4a0f-5db3-4e0e-ec73-ed8f1fd53f4f",
    "tags": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "******************************\n",
      "Config:\n",
      "blurpool/num_blurconv_layers: 0\n",
      "blurpool/num_blurpool_layers: 0\n",
      "enabled_algorithms/BlurPool: true\n",
      "node_name: unknown because NODENAME environment variable not set\n",
      "num_gpus_per_node: 1\n",
      "num_nodes: 1\n",
      "rank_zero_seed: 3514876640\n",
      "\n",
      "******************************\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "e255774c16184fb3aee6d01301e8f3e8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "train          Epoch   0:    0%|| 0/1174 [00:00<?, ?ba/s]         "
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "../aten/src/ATen/native/cuda/Loss.cu:240: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [2,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:240: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [5,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:240: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [10,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:240: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [11,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:240: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [12,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:240: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [17,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:240: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [18,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:240: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [23,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:240: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [27,0,0] Assertion `t >= 0 && t < n_classes` failed.\n",
      "../aten/src/ATen/native/cuda/Loss.cu:240: nll_loss_forward_reduce_cuda_kernel_2d: block: [0,0,0], thread: [30,0,0] Assertion `t >= 0 && t < n_classes` failed.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Unique values in targets: tensor([  0,   2,   8,  12,  25,  32, 181, 236, 240, 267, 416],\n",
      "       device='cuda:0')\n",
      "Counts of unique values: tensor([21,  1,  2,  1,  1,  1,  1,  1,  1,  1,  1], device='cuda:0')\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 2\u001b[0m\n\u001b[1;32m      1\u001b[0m start_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[0;32m----> 2\u001b[0m \u001b[43mtrainer\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;66;03m# <-- Your training loop in action!\u001b[39;00m\n\u001b[1;32m      3\u001b[0m end_time \u001b[38;5;241m=\u001b[39m time\u001b[38;5;241m.\u001b[39mperf_counter()\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mIt took \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mend_time\u001b[38;5;250m \u001b[39m\u001b[38;5;241m-\u001b[39m\u001b[38;5;250m \u001b[39mstart_time\u001b[38;5;132;01m:\u001b[39;00m\u001b[38;5;124m0.4f\u001b[39m\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m seconds to train\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/composer/trainer/trainer.py:1804\u001b[0m, in \u001b[0;36mTrainer.fit\u001b[0;34m(self, train_dataloader, train_dataloader_label, train_subset_num_batches, spin_dataloaders, duration, reset_time, schedulers, scale_schedule_ratio, step_schedulers_every_batch, eval_dataloader, eval_subset_num_batches, eval_interval, device_train_microbatch_size, precision)\u001b[0m\n\u001b[1;32m   1801\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mscaler \u001b[38;5;241m=\u001b[39m ClosureGradScaler() \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_use_closures() \u001b[38;5;28;01melse\u001b[39;00m GradScaler()\n\u001b[1;32m   1803\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mfirst_batch_complete \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m\n\u001b[0;32m-> 1804\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_loop\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/composer/trainer/trainer.py:1979\u001b[0m, in \u001b[0;36mTrainer._train_loop\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m   1976\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mlog_metrics({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime/token\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtimestamp\u001b[38;5;241m.\u001b[39mtoken\u001b[38;5;241m.\u001b[39mvalue})\n\u001b[1;32m   1977\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlogger\u001b[38;5;241m.\u001b[39mlog_metrics({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mtime/token_in_epoch\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mtimestamp\u001b[38;5;241m.\u001b[39mtoken_in_epoch\u001b[38;5;241m.\u001b[39mvalue})\n\u001b[0;32m-> 1979\u001b[0m total_loss_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_batch\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_grad_scaling\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1981\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m use_grad_scaling:\n\u001b[1;32m   1982\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mscaler\u001b[38;5;241m.\u001b[39mupdate()\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/composer/trainer/trainer.py:2166\u001b[0m, in \u001b[0;36mTrainer._train_batch\u001b[0;34m(self, use_grad_scaling)\u001b[0m\n\u001b[1;32m   2163\u001b[0m             optimizer\u001b[38;5;241m.\u001b[39mstep(closure\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mlambda\u001b[39;00m loss_dict\u001b[38;5;241m=\u001b[39mtotal_loss_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs: \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_train_microbatches(\n\u001b[1;32m   2164\u001b[0m                 microbatches, loss_dict, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)\u001b[38;5;241m.\u001b[39mitem())\n\u001b[1;32m   2165\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2166\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_microbatches\u001b[49m\u001b[43m(\u001b[49m\u001b[43mmicrobatches\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtotal_loss_dict\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2167\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mdeepspeed_enabled:\n\u001b[1;32m   2168\u001b[0m         \u001b[38;5;28;01mfor\u001b[39;00m optimizer \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39moptimizers:\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/composer/trainer/trainer.py:2266\u001b[0m, in \u001b[0;36mTrainer._train_microbatches\u001b[0;34m(self, microbatches, total_loss_dict, ddp_sync)\u001b[0m\n\u001b[1;32m   2264\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m microbatch_idx, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mbatch \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28menumerate\u001b[39m(microbatches):\n\u001b[1;32m   2265\u001b[0m     is_final_microbatch \u001b[38;5;241m=\u001b[39m microbatch_idx \u001b[38;5;241m+\u001b[39m \u001b[38;5;241m1\u001b[39m \u001b[38;5;241m==\u001b[39m \u001b[38;5;28mlen\u001b[39m(microbatches)\n\u001b[0;32m-> 2266\u001b[0m     microbatch_loss_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_train_microbatch\u001b[49m\u001b[43m(\u001b[49m\u001b[43muse_grad_scaling\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcurrent_batch_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mis_final_microbatch\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2268\u001b[0m     \u001b[38;5;66;03m# Aggregate each loss in microbatch_loss_dict into total_loss_dict\u001b[39;00m\n\u001b[1;32m   2269\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m k, microbatch_loss \u001b[38;5;129;01min\u001b[39;00m microbatch_loss_dict\u001b[38;5;241m.\u001b[39mitems():\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/composer/trainer/trainer.py:2366\u001b[0m, in \u001b[0;36mTrainer._train_microbatch\u001b[0;34m(self, use_grad_scaling, current_batch_size, is_final_microbatch)\u001b[0m\n\u001b[1;32m   2363\u001b[0m     microbatch_loss_dict \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mloss\u001b[38;5;241m.\u001b[39mcopy()\n\u001b[1;32m   2364\u001b[0m \u001b[38;5;66;03m# If total loss key is not present, sum individual losses\u001b[39;00m\n\u001b[1;32m   2365\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 2366\u001b[0m     microbatch_loss \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstate\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdevice\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtensor_to_device\u001b[49m\u001b[43m(\u001b[49m\u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mzeros\u001b[49m\u001b[43m(\u001b[49m\u001b[43msize\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   2367\u001b[0m     \u001b[38;5;28;01mfor\u001b[39;00m loss \u001b[38;5;129;01min\u001b[39;00m ensure_tuple(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mstate\u001b[38;5;241m.\u001b[39mloss):\n\u001b[1;32m   2368\u001b[0m         microbatch_loss\u001b[38;5;241m.\u001b[39madd_(loss\u001b[38;5;241m.\u001b[39mmean())\n",
      "File \u001b[0;32m~/anaconda3/envs/tensorflow2_p310/lib/python3.10/site-packages/composer/devices/device_gpu.py:59\u001b[0m, in \u001b[0;36mDeviceGPU.tensor_to_device\u001b[0;34m(self, tensor)\u001b[0m\n\u001b[1;32m     58\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mtensor_to_device\u001b[39m(\u001b[38;5;28mself\u001b[39m, tensor: torch\u001b[38;5;241m.\u001b[39mTensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch\u001b[38;5;241m.\u001b[39mTensor:\n\u001b[0;32m---> 59\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtensor\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mto\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_device\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mnon_blocking\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43;01mTrue\u001b[39;49;00m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mRuntimeError\u001b[0m: CUDA error: device-side assert triggered\nCUDA kernel errors might be asynchronously reported at some other API call, so the stacktrace below might be incorrect.\nFor debugging consider passing CUDA_LAUNCH_BLOCKING=1.\nCompile with `TORCH_USE_CUDA_DSA` to enable device-side assertions.\n"
     ]
    }
   ],
   "source": [
    "start_time = time.perf_counter()\n",
    "trainer.fit() # <-- Your training loop in action!\n",
    "end_time = time.perf_counter()\n",
    "print(f\"It took {end_time - start_time:0.4f} seconds to train\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "f0fKMiVyKq9J"
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "gpuType": "T4",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "conda_tensorflow2_p310",
   "language": "python",
   "name": "conda_tensorflow2_p310"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
